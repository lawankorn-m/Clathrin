{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 [==============================] - 17s 40ms/step - loss: 0.6861 - accuracy: 0.5478 - val_loss: 0.6850 - val_accuracy: 0.5596 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6814 - accuracy: 0.5581 - val_loss: 0.6577 - val_accuracy: 0.7064 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.6708 - accuracy: 0.5755 - val_loss: 0.5735 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.6325 - accuracy: 0.6413 - val_loss: 0.3601 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.5714 - accuracy: 0.7050 - val_loss: 0.2093 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.5509 - accuracy: 0.7256 - val_loss: 0.1903 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.4741 - accuracy: 0.7924 - val_loss: 0.1348 - val_accuracy: 0.9817 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.4583 - accuracy: 0.7934 - val_loss: 0.1102 - val_accuracy: 0.9817 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.4268 - accuracy: 0.8232 - val_loss: 0.1016 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3841 - accuracy: 0.8325 - val_loss: 0.0829 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3622 - accuracy: 0.8489 - val_loss: 0.0840 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3702 - accuracy: 0.8448 - val_loss: 0.0887 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3246 - accuracy: 0.8613 - val_loss: 0.0643 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3396 - accuracy: 0.8705 - val_loss: 0.0707 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3799 - accuracy: 0.8428 - val_loss: 0.0851 - val_accuracy: 0.9817 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3538 - accuracy: 0.8582 - val_loss: 0.0952 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3110 - accuracy: 0.8736 - val_loss: 0.1048 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3145 - accuracy: 0.8674 - val_loss: 0.0991 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3381 - accuracy: 0.8715 - val_loss: 0.1023 - val_accuracy: 0.9633 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3276 - accuracy: 0.8592 - val_loss: 0.1054 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2849 - accuracy: 0.8983 - val_loss: 0.1064 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.3194 - accuracy: 0.8869 - val_loss: 0.1127 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 3s 24ms/step - loss: 0.2819 - accuracy: 0.8952 - val_loss: 0.1070 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2882 - accuracy: 0.8890 - val_loss: 0.1085 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2875 - accuracy: 0.8900 - val_loss: 0.1093 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2935 - accuracy: 0.8890 - val_loss: 0.1082 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.2889 - accuracy: 0.8941 - val_loss: 0.1084 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2911 - accuracy: 0.8931 - val_loss: 0.1085 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.3130 - accuracy: 0.8756 - val_loss: 0.1071 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3003 - accuracy: 0.8787 - val_loss: 0.1079 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2789 - accuracy: 0.8921 - val_loss: 0.1088 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2759 - accuracy: 0.8993 - val_loss: 0.1057 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3030 - accuracy: 0.8798 - val_loss: 0.1054 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3084 - accuracy: 0.8767 - val_loss: 0.1081 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3162 - accuracy: 0.8808 - val_loss: 0.1062 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3344 - accuracy: 0.8818 - val_loss: 0.1059 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2887 - accuracy: 0.8900 - val_loss: 0.1074 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2658 - accuracy: 0.8952 - val_loss: 0.1062 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "0 CNN: acc=0.972477, precision=0.978723, npv=0.967742, sensitivity=0.958333, specificity=0.983607, mcc=0.944200, f1=0.968421, roc_auc=0.994877\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 16s 25ms/step - loss: 0.6910 - accuracy: 0.5488 - val_loss: 0.6848 - val_accuracy: 0.5596 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.6848 - accuracy: 0.5355 - val_loss: 0.6633 - val_accuracy: 0.5596 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.6572 - accuracy: 0.5889 - val_loss: 0.5545 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.6070 - accuracy: 0.6701 - val_loss: 0.3528 - val_accuracy: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.5602 - accuracy: 0.7287 - val_loss: 0.2525 - val_accuracy: 0.9450 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.5007 - accuracy: 0.7616 - val_loss: 0.2157 - val_accuracy: 0.9266 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.4604 - accuracy: 0.7914 - val_loss: 0.1613 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.4126 - accuracy: 0.8325 - val_loss: 0.1629 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.4249 - accuracy: 0.8243 - val_loss: 0.1456 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3698 - accuracy: 0.8561 - val_loss: 0.1480 - val_accuracy: 0.9450 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.3776 - accuracy: 0.8479 - val_loss: 0.1507 - val_accuracy: 0.9450 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3567 - accuracy: 0.8582 - val_loss: 0.1396 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3623 - accuracy: 0.8438 - val_loss: 0.1318 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3196 - accuracy: 0.8746 - val_loss: 0.1436 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3505 - accuracy: 0.8623 - val_loss: 0.1358 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3197 - accuracy: 0.8839 - val_loss: 0.1307 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3410 - accuracy: 0.8592 - val_loss: 0.1339 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2979 - accuracy: 0.8941 - val_loss: 0.1297 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2847 - accuracy: 0.8900 - val_loss: 0.1312 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3016 - accuracy: 0.8890 - val_loss: 0.1392 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2841 - accuracy: 0.8828 - val_loss: 0.1390 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2803 - accuracy: 0.8962 - val_loss: 0.1376 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2878 - accuracy: 0.8931 - val_loss: 0.1193 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2995 - accuracy: 0.8890 - val_loss: 0.1334 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2551 - accuracy: 0.9147 - val_loss: 0.1363 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2934 - accuracy: 0.8787 - val_loss: 0.1277 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2848 - accuracy: 0.8952 - val_loss: 0.1220 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2639 - accuracy: 0.9085 - val_loss: 0.1277 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2879 - accuracy: 0.8921 - val_loss: 0.1224 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.2600 - accuracy: 0.9116 - val_loss: 0.1256 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2490 - accuracy: 0.9085 - val_loss: 0.1293 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2361 - accuracy: 0.9126 - val_loss: 0.1176 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2290 - accuracy: 0.9239 - val_loss: 0.1287 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2550 - accuracy: 0.9085 - val_loss: 0.1296 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2317 - accuracy: 0.9219 - val_loss: 0.1341 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2527 - accuracy: 0.9157 - val_loss: 0.1319 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2425 - accuracy: 0.9075 - val_loss: 0.1309 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2312 - accuracy: 0.9281 - val_loss: 0.1348 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2669 - accuracy: 0.9065 - val_loss: 0.1339 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2603 - accuracy: 0.9003 - val_loss: 0.1368 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2412 - accuracy: 0.9126 - val_loss: 0.1362 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2798 - accuracy: 0.8983 - val_loss: 0.1286 - val_accuracy: 0.9541 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2380 - accuracy: 0.9188 - val_loss: 0.1283 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2347 - accuracy: 0.9106 - val_loss: 0.1321 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2207 - accuracy: 0.9157 - val_loss: 0.1324 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.1876 - accuracy: 0.9311 - val_loss: 0.1251 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2608 - accuracy: 0.9116 - val_loss: 0.1297 - val_accuracy: 0.9541 - lr: 4.0000e-06\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2359 - accuracy: 0.9168 - val_loss: 0.1222 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2086 - accuracy: 0.9198 - val_loss: 0.1262 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2382 - accuracy: 0.9209 - val_loss: 0.1300 - val_accuracy: 0.9541 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 3s 8ms/step\n",
      "1 CNN: acc=0.935780, precision=0.936170, npv=0.935484, sensitivity=0.916667, specificity=0.950820, mcc=0.869568, f1=0.926316, roc_auc=0.984631\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 26ms/step - loss: 0.6886 - accuracy: 0.5544 - val_loss: 0.6826 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.6820 - accuracy: 0.5575 - val_loss: 0.6564 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.6600 - accuracy: 0.6006 - val_loss: 0.5552 - val_accuracy: 0.9352 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.6307 - accuracy: 0.6314 - val_loss: 0.3916 - val_accuracy: 0.9074 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.5739 - accuracy: 0.7012 - val_loss: 0.3095 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.4680 - accuracy: 0.7844 - val_loss: 0.2582 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.4640 - accuracy: 0.7875 - val_loss: 0.2246 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.4676 - accuracy: 0.7988 - val_loss: 0.2005 - val_accuracy: 0.9259 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.4119 - accuracy: 0.8368 - val_loss: 0.1879 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.4004 - accuracy: 0.8480 - val_loss: 0.1749 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3523 - accuracy: 0.8552 - val_loss: 0.1732 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3730 - accuracy: 0.8429 - val_loss: 0.1576 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3412 - accuracy: 0.8542 - val_loss: 0.1683 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3279 - accuracy: 0.8758 - val_loss: 0.1530 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3246 - accuracy: 0.8676 - val_loss: 0.1505 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3116 - accuracy: 0.8768 - val_loss: 0.1739 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3323 - accuracy: 0.8686 - val_loss: 0.1517 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.3028 - accuracy: 0.8799 - val_loss: 0.1609 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.3009 - accuracy: 0.8881 - val_loss: 0.1549 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3090 - accuracy: 0.8850 - val_loss: 0.1462 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2881 - accuracy: 0.8953 - val_loss: 0.1514 - val_accuracy: 0.9722 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2980 - accuracy: 0.8901 - val_loss: 0.1528 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2659 - accuracy: 0.9045 - val_loss: 0.1449 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2843 - accuracy: 0.8973 - val_loss: 0.1372 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3058 - accuracy: 0.8809 - val_loss: 0.1324 - val_accuracy: 0.9722 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3388 - accuracy: 0.8696 - val_loss: 0.1641 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2747 - accuracy: 0.9014 - val_loss: 0.1511 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2529 - accuracy: 0.9066 - val_loss: 0.1547 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2377 - accuracy: 0.9138 - val_loss: 0.1591 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2905 - accuracy: 0.8932 - val_loss: 0.1346 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2598 - accuracy: 0.9055 - val_loss: 0.1340 - val_accuracy: 0.9630 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2645 - accuracy: 0.9025 - val_loss: 0.1339 - val_accuracy: 0.9630 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2952 - accuracy: 0.8881 - val_loss: 0.1322 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2373 - accuracy: 0.9138 - val_loss: 0.1321 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 0.2159 - accuracy: 0.9179 - val_loss: 0.1328 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2304 - accuracy: 0.9333 - val_loss: 0.1381 - val_accuracy: 0.9630 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2530 - accuracy: 0.9107 - val_loss: 0.1326 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2682 - accuracy: 0.9025 - val_loss: 0.1346 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2451 - accuracy: 0.9086 - val_loss: 0.1347 - val_accuracy: 0.9722 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2394 - accuracy: 0.9168 - val_loss: 0.1360 - val_accuracy: 0.9722 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2126 - accuracy: 0.9261 - val_loss: 0.1351 - val_accuracy: 0.9722 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2328 - accuracy: 0.9168 - val_loss: 0.1345 - val_accuracy: 0.9722 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.2286 - accuracy: 0.9148 - val_loss: 0.1362 - val_accuracy: 0.9722 - lr: 2.0000e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2179 - accuracy: 0.9230 - val_loss: 0.1379 - val_accuracy: 0.9630 - lr: 4.0000e-06\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2551 - accuracy: 0.9025 - val_loss: 0.1368 - val_accuracy: 0.9722 - lr: 4.0000e-06\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2680 - accuracy: 0.9035 - val_loss: 0.1344 - val_accuracy: 0.9722 - lr: 4.0000e-06\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2679 - accuracy: 0.8973 - val_loss: 0.1370 - val_accuracy: 0.9630 - lr: 4.0000e-06\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2287 - accuracy: 0.9220 - val_loss: 0.1347 - val_accuracy: 0.9722 - lr: 4.0000e-06\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2430 - accuracy: 0.9199 - val_loss: 0.1363 - val_accuracy: 0.9722 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2453 - accuracy: 0.9117 - val_loss: 0.1392 - val_accuracy: 0.9630 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 2s 7ms/step\n",
      "2 CNN: acc=0.953704, precision=0.957447, npv=0.950820, sensitivity=0.937500, specificity=0.966667, mcc=0.906214, f1=0.947368, roc_auc=0.964931\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 23s 49ms/step - loss: 0.6915 - accuracy: 0.5308 - val_loss: 0.6865 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6806 - accuracy: 0.5637 - val_loss: 0.6722 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.6732 - accuracy: 0.5729 - val_loss: 0.6058 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.6427 - accuracy: 0.6335 - val_loss: 0.4239 - val_accuracy: 0.9722 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.5500 - accuracy: 0.7300 - val_loss: 0.2341 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.5331 - accuracy: 0.7351 - val_loss: 0.2010 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.5014 - accuracy: 0.7639 - val_loss: 0.1843 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.4585 - accuracy: 0.7926 - val_loss: 0.1649 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.4446 - accuracy: 0.8111 - val_loss: 0.1484 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.4394 - accuracy: 0.8039 - val_loss: 0.1533 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3523 - accuracy: 0.8491 - val_loss: 0.1260 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3709 - accuracy: 0.8480 - val_loss: 0.1365 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3728 - accuracy: 0.8593 - val_loss: 0.1125 - val_accuracy: 0.9722 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3557 - accuracy: 0.8624 - val_loss: 0.1051 - val_accuracy: 0.9722 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3763 - accuracy: 0.8532 - val_loss: 0.1334 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3244 - accuracy: 0.8665 - val_loss: 0.1146 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.3631 - accuracy: 0.8532 - val_loss: 0.1154 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3053 - accuracy: 0.8830 - val_loss: 0.1021 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3055 - accuracy: 0.8737 - val_loss: 0.0964 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3326 - accuracy: 0.8686 - val_loss: 0.1004 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2944 - accuracy: 0.8891 - val_loss: 0.0920 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3367 - accuracy: 0.8778 - val_loss: 0.0956 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.3178 - accuracy: 0.8799 - val_loss: 0.0951 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2542 - accuracy: 0.9179 - val_loss: 0.0878 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2680 - accuracy: 0.9004 - val_loss: 0.0894 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.2836 - accuracy: 0.8881 - val_loss: 0.0844 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2910 - accuracy: 0.8881 - val_loss: 0.0900 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2613 - accuracy: 0.9014 - val_loss: 0.0861 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2676 - accuracy: 0.8994 - val_loss: 0.0915 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3035 - accuracy: 0.8850 - val_loss: 0.1045 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2433 - accuracy: 0.9179 - val_loss: 0.0898 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2901 - accuracy: 0.8891 - val_loss: 0.0905 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2655 - accuracy: 0.9014 - val_loss: 0.0939 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2689 - accuracy: 0.8994 - val_loss: 0.0918 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2695 - accuracy: 0.9004 - val_loss: 0.0930 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2713 - accuracy: 0.9004 - val_loss: 0.0966 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2748 - accuracy: 0.8973 - val_loss: 0.0973 - val_accuracy: 0.9815 - lr: 2.0000e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2510 - accuracy: 0.9168 - val_loss: 0.0957 - val_accuracy: 0.9815 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2431 - accuracy: 0.9097 - val_loss: 0.0972 - val_accuracy: 0.9815 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 0.2499 - accuracy: 0.9004 - val_loss: 0.0956 - val_accuracy: 0.9815 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2608 - accuracy: 0.8994 - val_loss: 0.0946 - val_accuracy: 0.9815 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2406 - accuracy: 0.9138 - val_loss: 0.0953 - val_accuracy: 0.9815 - lr: 4.0000e-06\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2342 - accuracy: 0.9097 - val_loss: 0.0959 - val_accuracy: 0.9815 - lr: 4.0000e-06\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2826 - accuracy: 0.8932 - val_loss: 0.0951 - val_accuracy: 0.9815 - lr: 4.0000e-06\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2401 - accuracy: 0.9240 - val_loss: 0.0945 - val_accuracy: 0.9815 - lr: 4.0000e-06\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2601 - accuracy: 0.9066 - val_loss: 0.0946 - val_accuracy: 0.9815 - lr: 4.0000e-06\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2622 - accuracy: 0.9025 - val_loss: 0.0949 - val_accuracy: 0.9815 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.2229 - accuracy: 0.9168 - val_loss: 0.0944 - val_accuracy: 0.9815 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2456 - accuracy: 0.9117 - val_loss: 0.0944 - val_accuracy: 0.9815 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 0.2670 - accuracy: 0.9045 - val_loss: 0.0946 - val_accuracy: 0.9815 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 3s 21ms/step\n",
      "3 CNN: acc=0.981481, precision=0.960000, npv=1.000000, sensitivity=1.000000, specificity=0.966667, mcc=0.963328, f1=0.979592, roc_auc=1.000000\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 15s 39ms/step - loss: 0.6935 - accuracy: 0.5133 - val_loss: 0.6870 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.6811 - accuracy: 0.5595 - val_loss: 0.6721 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.6765 - accuracy: 0.5678 - val_loss: 0.6298 - val_accuracy: 0.8519 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.6630 - accuracy: 0.5996 - val_loss: 0.5171 - val_accuracy: 0.9259 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.5934 - accuracy: 0.6797 - val_loss: 0.3113 - val_accuracy: 0.8796 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.5327 - accuracy: 0.7290 - val_loss: 0.2537 - val_accuracy: 0.8889 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.4808 - accuracy: 0.7741 - val_loss: 0.1694 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.4749 - accuracy: 0.7823 - val_loss: 0.1673 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.1475 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.4442 - accuracy: 0.7998 - val_loss: 0.1675 - val_accuracy: 0.9352 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.4189 - accuracy: 0.8162 - val_loss: 0.1608 - val_accuracy: 0.9352 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.4153 - accuracy: 0.8285 - val_loss: 0.1535 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3733 - accuracy: 0.8419 - val_loss: 0.1336 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.3640 - accuracy: 0.8686 - val_loss: 0.1333 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.3222 - accuracy: 0.8696 - val_loss: 0.1298 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3427 - accuracy: 0.8614 - val_loss: 0.1416 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3139 - accuracy: 0.8891 - val_loss: 0.1455 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2995 - accuracy: 0.8819 - val_loss: 0.1283 - val_accuracy: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3269 - accuracy: 0.8717 - val_loss: 0.1387 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3288 - accuracy: 0.8830 - val_loss: 0.1537 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3385 - accuracy: 0.8634 - val_loss: 0.1607 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2599 - accuracy: 0.9107 - val_loss: 0.1615 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2951 - accuracy: 0.8912 - val_loss: 0.1722 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2733 - accuracy: 0.8953 - val_loss: 0.1720 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2828 - accuracy: 0.8994 - val_loss: 0.1678 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2866 - accuracy: 0.8891 - val_loss: 0.1581 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2682 - accuracy: 0.9076 - val_loss: 0.1606 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2829 - accuracy: 0.8932 - val_loss: 0.1583 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2797 - accuracy: 0.9004 - val_loss: 0.1588 - val_accuracy: 0.9537 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2830 - accuracy: 0.8922 - val_loss: 0.1593 - val_accuracy: 0.9537 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3011 - accuracy: 0.8860 - val_loss: 0.1573 - val_accuracy: 0.9537 - lr: 2.0000e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2682 - accuracy: 0.8984 - val_loss: 0.1579 - val_accuracy: 0.9537 - lr: 2.0000e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2593 - accuracy: 0.9076 - val_loss: 0.1570 - val_accuracy: 0.9537 - lr: 2.0000e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2620 - accuracy: 0.9025 - val_loss: 0.1580 - val_accuracy: 0.9537 - lr: 4.0000e-06\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2733 - accuracy: 0.9004 - val_loss: 0.1581 - val_accuracy: 0.9537 - lr: 4.0000e-06\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2782 - accuracy: 0.8943 - val_loss: 0.1580 - val_accuracy: 0.9537 - lr: 4.0000e-06\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2431 - accuracy: 0.9127 - val_loss: 0.1589 - val_accuracy: 0.9537 - lr: 4.0000e-06\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2872 - accuracy: 0.8840 - val_loss: 0.1588 - val_accuracy: 0.9537 - lr: 4.0000e-06\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2694 - accuracy: 0.8963 - val_loss: 0.1572 - val_accuracy: 0.9537 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2727 - accuracy: 0.9055 - val_loss: 0.1575 - val_accuracy: 0.9537 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2722 - accuracy: 0.8984 - val_loss: 0.1582 - val_accuracy: 0.9537 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2725 - accuracy: 0.8973 - val_loss: 0.1584 - val_accuracy: 0.9537 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2856 - accuracy: 0.8953 - val_loss: 0.1583 - val_accuracy: 0.9537 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4 CNN: acc=0.953704, precision=0.938775, npv=0.966102, sensitivity=0.958333, specificity=0.950000, mcc=0.906604, f1=0.948454, roc_auc=0.992708\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 16s 37ms/step - loss: 0.6934 - accuracy: 0.5216 - val_loss: 0.6854 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.6844 - accuracy: 0.5626 - val_loss: 0.6656 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.6746 - accuracy: 0.5616 - val_loss: 0.6187 - val_accuracy: 0.9259 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.6462 - accuracy: 0.6170 - val_loss: 0.4622 - val_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.5854 - accuracy: 0.6797 - val_loss: 0.2858 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.5347 - accuracy: 0.7238 - val_loss: 0.2468 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.5121 - accuracy: 0.7361 - val_loss: 0.2545 - val_accuracy: 0.9074 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.4971 - accuracy: 0.7608 - val_loss: 0.2146 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.4238 - accuracy: 0.8172 - val_loss: 0.2173 - val_accuracy: 0.8981 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.4114 - accuracy: 0.8224 - val_loss: 0.1823 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.4019 - accuracy: 0.8337 - val_loss: 0.1641 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3697 - accuracy: 0.8378 - val_loss: 0.1567 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3736 - accuracy: 0.8563 - val_loss: 0.1560 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3673 - accuracy: 0.8460 - val_loss: 0.1602 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.3606 - accuracy: 0.8532 - val_loss: 0.1555 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3470 - accuracy: 0.8696 - val_loss: 0.1681 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3626 - accuracy: 0.8491 - val_loss: 0.1604 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3261 - accuracy: 0.8717 - val_loss: 0.1588 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3263 - accuracy: 0.8665 - val_loss: 0.1722 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3466 - accuracy: 0.8717 - val_loss: 0.1785 - val_accuracy: 0.9444 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2899 - accuracy: 0.9025 - val_loss: 0.1770 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3009 - accuracy: 0.8809 - val_loss: 0.1799 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2935 - accuracy: 0.8830 - val_loss: 0.1788 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2984 - accuracy: 0.8840 - val_loss: 0.1730 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2902 - accuracy: 0.8973 - val_loss: 0.1683 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.3015 - accuracy: 0.8830 - val_loss: 0.1673 - val_accuracy: 0.9444 - lr: 2.0000e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2667 - accuracy: 0.9035 - val_loss: 0.1681 - val_accuracy: 0.9444 - lr: 2.0000e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2971 - accuracy: 0.8891 - val_loss: 0.1697 - val_accuracy: 0.9444 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 0.2931 - accuracy: 0.8901 - val_loss: 0.1697 - val_accuracy: 0.9444 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2972 - accuracy: 0.8922 - val_loss: 0.1686 - val_accuracy: 0.9444 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.3141 - accuracy: 0.8758 - val_loss: 0.1691 - val_accuracy: 0.9444 - lr: 4.0000e-06\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.2772 - accuracy: 0.8984 - val_loss: 0.1670 - val_accuracy: 0.9444 - lr: 4.0000e-06\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2855 - accuracy: 0.8881 - val_loss: 0.1686 - val_accuracy: 0.9444 - lr: 4.0000e-06\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2778 - accuracy: 0.8922 - val_loss: 0.1691 - val_accuracy: 0.9444 - lr: 4.0000e-06\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.2963 - accuracy: 0.8963 - val_loss: 0.1699 - val_accuracy: 0.9444 - lr: 4.0000e-06\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2861 - accuracy: 0.8830 - val_loss: 0.1684 - val_accuracy: 0.9444 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2528 - accuracy: 0.9035 - val_loss: 0.1690 - val_accuracy: 0.9444 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.2817 - accuracy: 0.8891 - val_loss: 0.1706 - val_accuracy: 0.9444 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.2835 - accuracy: 0.8922 - val_loss: 0.1702 - val_accuracy: 0.9444 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3059 - accuracy: 0.8789 - val_loss: 0.1694 - val_accuracy: 0.9444 - lr: 1.0000e-06\n",
      "4/4 [==============================] - 2s 7ms/step\n",
      "5 CNN: acc=0.944444, precision=0.920000, npv=0.965517, sensitivity=0.958333, specificity=0.933333, mcc=0.888587, f1=0.938776, roc_auc=0.980556\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 15s 40ms/step - loss: 0.6874 - accuracy: 0.5400 - val_loss: 0.6856 - val_accuracy: 0.5556 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 0.6810 - accuracy: 0.5719 - val_loss: 0.6523 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      " 85/122 [===================>..........] - ETA: 0s - loss: 0.6661 - accuracy: 0.5691"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dropout, Flatten, Dense, BatchNormalization, Attention\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, BatchNormalization, Flatten, Dense, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "# Function to map categorical probabilities to class labels\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def calculate_performance(test_num, pred_y, labels):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] == 1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    acc = (tp + tn) / test_num\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    npv = tn / (tn + fn + 1e-6)\n",
    "    sensitivity = tp / (tp + fn + 1e-6)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    mcc = (tp * tn - fp * fn) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + 1e-6)\n",
    "    f1 = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "    return acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn\n",
    "\n",
    "# Function to define and return the CNN-BiLSTM model\n",
    "def get_CNN_model_with_attention(input_dim, out_dim):\n",
    "    # Define the input\n",
    "    inputs = Input(shape=(1, input_dim))\n",
    "\n",
    "    # LSTM layers\n",
    "    lstm_1 = LSTM(int(input_dim/2), return_sequences=True)(inputs)\n",
    "    dropout_1 = Dropout(0.7)(lstm_1)\n",
    "    batchnorm_1 = BatchNormalization()(dropout_1)\n",
    "\n",
    "    lstm_2 = LSTM(int(input_dim/4), return_sequences=True)(batchnorm_1)\n",
    "    dropout_2 = Dropout(0.7)(lstm_2)\n",
    "    batchnorm_2 = BatchNormalization()(dropout_2)\n",
    "\n",
    "    lstm_3 = LSTM(int(input_dim/8), return_sequences=False)(batchnorm_2)\n",
    "    dropout_3 = Dropout(0.7)(lstm_3)\n",
    "\n",
    "    # Attention mechanism (modified to use functional API)\n",
    "    attention = Attention()([dropout_3, dropout_3])  \n",
    "\n",
    "    # Fully connected layers\n",
    "    flatten = Flatten()(attention)\n",
    "    dense_1 = Dense(int(input_dim/4), activation='relu')(flatten)\n",
    "    dense_2 = Dense(int(input_dim/8), activation='relu')(dense_1)\n",
    "    output = Dense(out_dim, activation='softmax', name=\"Dense_2\")(dense_2)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Folder containing CSV files\n",
    "input_dir = './cla06/'\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file_name in csv_files:\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    output_base_dir = f\"./2024LSTM_{file_name}/\"\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    data_ = pd.read_csv(os.path.join(input_dir, file_name))\n",
    "\n",
    "    data = data_.iloc[:, 1:]\n",
    "    data = data.loc[0:1081]\n",
    "    \n",
    "    ones_vector1 = np.ones(480)\n",
    "    zeros_vector1 = np.zeros(602)\n",
    "    y = np.hstack((ones_vector1, zeros_vector1))\n",
    "\n",
    "    X = scale(data)\n",
    "\n",
    "    sepscores = []\n",
    "    ytest = np.ones((1, 2)) * 0.5\n",
    "    yscore = np.ones((1, 2)) * 0.5\n",
    "\n",
    "    [sample_num, input_dim] = np.shape(X)\n",
    "    out_dim = 2\n",
    "\n",
    "    probas_cnn = []\n",
    "    tprs_cnn = []\n",
    "    sepscore_cnn = []\n",
    "\n",
    "    # Callbacks for model training\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "    call = [EarlyStopping(monitor='val_loss', patience=25), reduce_lr]\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for i, (train, test) in enumerate(skf.split(X, y)):\n",
    "        #clf_cnn = get_CNN_model(input_dim, out_dim)\n",
    "        clf_cnn = get_CNN_model_with_attention(input_dim, out_dim)\n",
    "        X_train_cnn = np.reshape(X[train], (-1, 1, input_dim))\n",
    "        X_test_cnn = np.reshape(X[test], (-1, 1, input_dim))\n",
    "        y_test = to_categorical(y[test])\n",
    "        ytest = np.vstack((ytest, y_test))\n",
    "        y_test_tmp = y[test]\n",
    "\n",
    "        # Training\n",
    "        history = clf_cnn.fit(X_train_cnn, to_categorical(y[train]), validation_data=(X_test_cnn, y_test),\n",
    "                              batch_size=8, epochs=50, callbacks=call)\n",
    "\n",
    "        # Prediction\n",
    "        y_cnn_probas = clf_cnn.predict(X_test_cnn)\n",
    "        probas_cnn.append(y_cnn_probas)\n",
    "        y_class = np.argmax(y_cnn_probas, axis=1)\n",
    "        yscore = np.vstack((yscore, y_cnn_probas))\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn = calculate_performance(len(y_class), y_class, y[test])\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], y_cnn_probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        sepscore_cnn.append([acc, precision, npv, sensitivity, specificity, mcc, f1, roc_auc, tp, tn, fp, fn])\n",
    "        print(f'{i} CNN: acc={acc:.6f}, precision={precision:.6f}, npv={npv:.6f}, sensitivity={sensitivity:.6f}, '\n",
    "              f'specificity={specificity:.6f}, mcc={mcc:.6f}, f1={f1:.6f}, roc_auc={roc_auc:.6f}')\n",
    "\n",
    "        # Save the model\n",
    "        model_json = clf_cnn.to_json()\n",
    "        with open(f\"{output_base_dir}/CNN_BiLSTM_{str(i)}model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        clf_cnn.save_weights(f\"{output_base_dir}/CNN_BiLSTM_{str(i)}model.weights.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "    # Save ytest and yscore to CSV\n",
    "    row = ytest.shape[0]\n",
    "    ytest = ytest[np.array(range(1, row)), :]\n",
    "    ytest_sum = pd.DataFrame(data=ytest)\n",
    "    ytest_sum.to_csv(f'{output_base_dir}/ytest.csv')\n",
    "\n",
    "    yscore_ = yscore[np.array(range(1, row)), :]\n",
    "    yscore_sum = pd.DataFrame(data=yscore_)\n",
    "    yscore_sum.to_csv(f'{output_base_dir}/yscore.csv')\n",
    "\n",
    "    # Save results of cross-validation\n",
    "    scores = np.array(sepscore_cnn)\n",
    "    result1 = np.mean(scores, axis=0)\n",
    "    H1 = result1.tolist()\n",
    "    sepscore_cnn.append(H1)\n",
    "    result = sepscore_cnn\n",
    "    data_csv = pd.DataFrame(data=result, columns=['acc', 'precision', 'npv', 'sensitivity', 'specificity', 'mcc', 'f1', 'roc_auc', 'tp', 'tn', 'fp', 'fn'])\n",
    "    data_csv.to_csv(f'{output_base_dir}/results_CV.csv', index=False)\n",
    "\n",
    "    print(history)\n",
    "\n",
    "    # Testing phase with another part of data\n",
    "    test_data = data_.iloc[:, 1:]\n",
    "    test_data = test_data.loc[1082:]\n",
    "\n",
    "    ones_vector = np.ones(69)\n",
    "    zeros_vector = np.zeros(110)\n",
    "    yt = np.hstack((ones_vector, zeros_vector))\n",
    "\n",
    "    Xt = scale(test_data)\n",
    "    Xt = np.reshape(Xt, (-1, 1, input_dim))\n",
    "\n",
    "    sepscores = []\n",
    "    ytest = np.ones((1, 2)) * 0.5\n",
    "    yscore = np.ones((1, 2)) * 0.5\n",
    "\n",
    "    # Load and test saved models\n",
    "    for i in range(10):\n",
    "        with open(f\"{output_base_dir}CNN_BiLSTM_{str(i)}model.json\", 'r') as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        loaded_model.load_weights(f\"{output_base_dir}CNN_BiLSTM_{i}model.weights.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        y_score = loaded_model.predict(Xt)\n",
    "        y_class = categorical_probas_to_classes(y_score)\n",
    "\n",
    "        y_test = to_categorical(yt)\n",
    "        acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn = calculate_performance(len(y_class), y_class, yt)\n",
    "        fpr, tpr, thresholds = roc_curve(yt, y_score[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        sepscores.append([acc, precision, npv, sensitivity, specificity, mcc, f1, roc_auc, tp, tn, fp, fn])\n",
    "        print(f'{i} CNN Test: acc={acc:.6f}, precision={precision:.6f}, npv={npv:.6f}, sensitivity={sensitivity:.6f}, '\n",
    "              f'specificity={specificity:.6f}, mcc={mcc:.6f}, f1={f1:.6f}, roc_auc={roc_auc:.6f}')\n",
    "\n",
    "        # Save prediction results\n",
    "        ytest = np.vstack((ytest, y_test))\n",
    "        yscore = np.vstack((yscore, y_score))\n",
    "\n",
    "    # Save testing results\n",
    "    row = ytest.shape[0]\n",
    "    ytest = ytest[np.array(range(1, row)), :]\n",
    "    ytest_sum = pd.DataFrame(data=ytest)\n",
    "    ytest_sum.to_csv(f'{output_base_dir}/ytest_test.csv')\n",
    "\n",
    "    yscore_ = yscore[np.array(range(1, row)), :]\n",
    "    yscore_sum = pd.DataFrame(data=yscore_)\n",
    "    yscore_sum.to_csv(f'{output_base_dir}/yscore_test.csv')\n",
    "\n",
    "    # Save testing results of cross-validation\n",
    "    scores = np.array(sepscores)\n",
    "    result1 = np.mean(scores, axis=0)\n",
    "    H1 = result1.tolist()\n",
    "    sepscores.append(H1)\n",
    "    result = sepscores\n",
    "    data_csv = pd.DataFrame(data=result, columns=['acc', 'precision', 'npv', 'sensitivity', 'specificity', 'mcc', 'f1', 'roc_auc', 'tp', 'tn', 'fp', 'fn'])\n",
    "    data_csv.to_csv(f'{output_base_dir}/results_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 [==============================] - 20s 24ms/step - loss: 0.4548 - accuracy: 0.7688 - val_loss: 0.3848 - val_accuracy: 0.8716 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1673 - accuracy: 0.9476 - val_loss: 0.4357 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1117 - accuracy: 0.9651 - val_loss: 0.4398 - val_accuracy: 0.8532 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0889 - accuracy: 0.9671 - val_loss: 0.3967 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 0.9753 - val_loss: 0.3936 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 0.4079 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.3943 - val_accuracy: 0.9083 - lr: 2.0000e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0328 - accuracy: 0.9846 - val_loss: 0.4040 - val_accuracy: 0.9174 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.4197 - val_accuracy: 0.9174 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.4193 - val_accuracy: 0.9174 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0293 - accuracy: 0.9877 - val_loss: 0.4558 - val_accuracy: 0.9174 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.4564 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.4648 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.4712 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.4705 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.4685 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.4686 - val_accuracy: 0.9083 - lr: 8.0000e-06\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0177 - accuracy: 0.9918 - val_loss: 0.4693 - val_accuracy: 0.9083 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9928 - val_loss: 0.4710 - val_accuracy: 0.9083 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.4723 - val_accuracy: 0.9083 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.4711 - val_accuracy: 0.9083 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.4712 - val_accuracy: 0.9083 - lr: 1.6000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.4714 - val_accuracy: 0.9083 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.4715 - val_accuracy: 0.9083 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9938 - val_loss: 0.4716 - val_accuracy: 0.9083 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0244 - accuracy: 0.9897 - val_loss: 0.4715 - val_accuracy: 0.9083 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "0 CNN CV: acc=0.908257, precision=0.931818, npv=0.892308, sensitivity=0.854167, specificity=0.950820, mcc=0.814500, f1=0.891304, roc_auc=0.949112\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 21s 36ms/step - loss: 0.4945 - accuracy: 0.7554 - val_loss: 0.2163 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.1951 - accuracy: 0.9270 - val_loss: 0.1983 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.1394 - accuracy: 0.9507 - val_loss: 0.1712 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9702 - val_loss: 0.1767 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.2255 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0718 - accuracy: 0.9733 - val_loss: 0.1711 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0701 - accuracy: 0.9743 - val_loss: 0.1777 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.2468 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0603 - accuracy: 0.9764 - val_loss: 0.2533 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0371 - accuracy: 0.9836 - val_loss: 0.2519 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0574 - accuracy: 0.9784 - val_loss: 0.1900 - val_accuracy: 0.9358 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 0.1911 - val_accuracy: 0.9358 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0360 - accuracy: 0.9897 - val_loss: 0.1980 - val_accuracy: 0.9358 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0285 - accuracy: 0.9866 - val_loss: 0.2066 - val_accuracy: 0.9358 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0222 - accuracy: 0.9908 - val_loss: 0.2074 - val_accuracy: 0.9450 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 0.2347 - val_accuracy: 0.9358 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0201 - accuracy: 0.9908 - val_loss: 0.2321 - val_accuracy: 0.9358 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.2310 - val_accuracy: 0.9358 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.2322 - val_accuracy: 0.9358 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 0.2342 - val_accuracy: 0.9358 - lr: 4.0000e-05\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0151 - accuracy: 0.9938 - val_loss: 0.2357 - val_accuracy: 0.9358 - lr: 4.0000e-05\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.2360 - val_accuracy: 0.9358 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0192 - accuracy: 0.9897 - val_loss: 0.2366 - val_accuracy: 0.9358 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0257 - accuracy: 0.9897 - val_loss: 0.2381 - val_accuracy: 0.9358 - lr: 8.0000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.2386 - val_accuracy: 0.9358 - lr: 8.0000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0243 - accuracy: 0.9897 - val_loss: 0.2383 - val_accuracy: 0.9358 - lr: 8.0000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0201 - accuracy: 0.9918 - val_loss: 0.2382 - val_accuracy: 0.9358 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 0.2383 - val_accuracy: 0.9358 - lr: 1.6000e-06\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.2384 - val_accuracy: 0.9358 - lr: 1.6000e-06\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.2381 - val_accuracy: 0.9358 - lr: 1.6000e-06\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0194 - accuracy: 0.9908 - val_loss: 0.2382 - val_accuracy: 0.9358 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 2s 0s/step\n",
      "1 CNN CV: acc=0.935780, precision=0.918367, npv=0.950000, sensitivity=0.937500, specificity=0.934426, mcc=0.870145, f1=0.927835, roc_auc=0.981216\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 23ms/step - loss: 0.4854 - accuracy: 0.7628 - val_loss: 0.2646 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1709 - accuracy: 0.9435 - val_loss: 0.2372 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1070 - accuracy: 0.9630 - val_loss: 0.2663 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1096 - accuracy: 0.9559 - val_loss: 0.3140 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.2872 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0651 - accuracy: 0.9784 - val_loss: 0.3013 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0701 - accuracy: 0.9754 - val_loss: 0.3889 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 0.9846 - val_loss: 0.3642 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.3742 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0292 - accuracy: 0.9867 - val_loss: 0.4171 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0237 - accuracy: 0.9856 - val_loss: 0.4221 - val_accuracy: 0.9074 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9908 - val_loss: 0.4241 - val_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9897 - val_loss: 0.4333 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0258 - accuracy: 0.9867 - val_loss: 0.4329 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.4386 - val_accuracy: 0.8796 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9908 - val_loss: 0.4408 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.4411 - val_accuracy: 0.8796 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 0.9877 - val_loss: 0.4418 - val_accuracy: 0.8796 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0196 - accuracy: 0.9918 - val_loss: 0.4420 - val_accuracy: 0.8796 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.9887 - val_loss: 0.4420 - val_accuracy: 0.8796 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0203 - accuracy: 0.9877 - val_loss: 0.4434 - val_accuracy: 0.8796 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0210 - accuracy: 0.9908 - val_loss: 0.4443 - val_accuracy: 0.8796 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0224 - accuracy: 0.9887 - val_loss: 0.4441 - val_accuracy: 0.8796 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0248 - accuracy: 0.9897 - val_loss: 0.4439 - val_accuracy: 0.8796 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 0.4442 - val_accuracy: 0.8796 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0235 - accuracy: 0.9887 - val_loss: 0.4444 - val_accuracy: 0.8796 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0220 - accuracy: 0.9918 - val_loss: 0.4446 - val_accuracy: 0.8796 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "2 CNN CV: acc=0.879630, precision=0.843137, npv=0.912281, sensitivity=0.895833, specificity=0.866667, mcc=0.758951, f1=0.868687, roc_auc=0.956944\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 18s 22ms/step - loss: 0.4820 - accuracy: 0.7495 - val_loss: 0.2794 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9261 - val_loss: 0.2226 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1192 - accuracy: 0.9569 - val_loss: 0.2863 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1022 - accuracy: 0.9682 - val_loss: 0.2857 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0636 - accuracy: 0.9784 - val_loss: 0.3178 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0698 - accuracy: 0.9764 - val_loss: 0.3451 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 0.3327 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0469 - accuracy: 0.9815 - val_loss: 0.3250 - val_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0391 - accuracy: 0.9846 - val_loss: 0.3104 - val_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0364 - accuracy: 0.9825 - val_loss: 0.3391 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0345 - accuracy: 0.9856 - val_loss: 0.3401 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.3327 - val_accuracy: 0.9074 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.3428 - val_accuracy: 0.8981 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.3512 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.3570 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.3603 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0237 - accuracy: 0.9908 - val_loss: 0.3695 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.3703 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 0.3720 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9918 - val_loss: 0.3733 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.3733 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.3760 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.3760 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.3760 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.3764 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.3764 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.3765 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 6s 27ms/step\n",
      "3 CNN CV: acc=0.888889, precision=0.846154, npv=0.928571, sensitivity=0.916667, specificity=0.866667, mcc=0.779017, f1=0.880000, roc_auc=0.969792\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 16s 35ms/step - loss: 0.4869 - accuracy: 0.7772 - val_loss: 0.2086 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.2005 - accuracy: 0.9230 - val_loss: 0.1655 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1328 - accuracy: 0.9538 - val_loss: 0.1059 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1024 - accuracy: 0.9661 - val_loss: 0.0867 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0725 - accuracy: 0.9754 - val_loss: 0.1008 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0789 - accuracy: 0.9754 - val_loss: 0.1379 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 0.1261 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: 0.0915 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0472 - accuracy: 0.9815 - val_loss: 0.1740 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0532 - accuracy: 0.9795 - val_loss: 0.1349 - val_accuracy: 0.9444 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0274 - accuracy: 0.9877 - val_loss: 0.1569 - val_accuracy: 0.9352 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 0.1668 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.0327 - accuracy: 0.9825 - val_loss: 0.1435 - val_accuracy: 0.9352 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0200 - accuracy: 0.9908 - val_loss: 0.1434 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0274 - accuracy: 0.9867 - val_loss: 0.1400 - val_accuracy: 0.9352 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0183 - accuracy: 0.9908 - val_loss: 0.1436 - val_accuracy: 0.9352 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0201 - accuracy: 0.9908 - val_loss: 0.1412 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0288 - accuracy: 0.9877 - val_loss: 0.1367 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.1369 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 0.1365 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9918 - val_loss: 0.1369 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.1360 - val_accuracy: 0.9630 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1358 - val_accuracy: 0.9630 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 0.1360 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0180 - accuracy: 0.9908 - val_loss: 0.1364 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0185 - accuracy: 0.9918 - val_loss: 0.1365 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1364 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9918 - val_loss: 0.1363 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0227 - accuracy: 0.9887 - val_loss: 0.1364 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4 CNN CV: acc=0.953704, precision=0.938775, npv=0.966102, sensitivity=0.958333, specificity=0.950000, mcc=0.906604, f1=0.948454, roc_auc=0.992361\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 18s 23ms/step - loss: 0.4767 - accuracy: 0.7854 - val_loss: 0.2049 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1871 - accuracy: 0.9353 - val_loss: 0.1626 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1340 - accuracy: 0.9507 - val_loss: 0.1226 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 0.1394 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0906 - accuracy: 0.9661 - val_loss: 0.1233 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0758 - accuracy: 0.9671 - val_loss: 0.1700 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0676 - accuracy: 0.9805 - val_loss: 0.2046 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0594 - accuracy: 0.9795 - val_loss: 0.1614 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0382 - accuracy: 0.9815 - val_loss: 0.1872 - val_accuracy: 0.9352 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.1941 - val_accuracy: 0.9352 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 0.1935 - val_accuracy: 0.9444 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.2038 - val_accuracy: 0.9352 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0323 - accuracy: 0.9856 - val_loss: 0.2095 - val_accuracy: 0.9444 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 0.9877 - val_loss: 0.2094 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 0.2124 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.2133 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0263 - accuracy: 0.9867 - val_loss: 0.2164 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 0.2184 - val_accuracy: 0.9444 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0205 - accuracy: 0.9897 - val_loss: 0.2192 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0263 - accuracy: 0.9867 - val_loss: 0.2193 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 0.2196 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.2203 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0206 - accuracy: 0.9908 - val_loss: 0.2218 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0179 - accuracy: 0.9918 - val_loss: 0.2218 - val_accuracy: 0.9444 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9887 - val_loss: 0.2219 - val_accuracy: 0.9444 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0167 - accuracy: 0.9938 - val_loss: 0.2220 - val_accuracy: 0.9444 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.2221 - val_accuracy: 0.9444 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0240 - accuracy: 0.9867 - val_loss: 0.2221 - val_accuracy: 0.9444 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 2s 0s/step\n",
      "5 CNN CV: acc=0.944444, precision=0.937500, npv=0.950000, sensitivity=0.937500, specificity=0.950000, mcc=0.887500, f1=0.937500, roc_auc=0.993403\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 22s 22ms/step - loss: 0.4902 - accuracy: 0.7464 - val_loss: 0.2917 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1815 - accuracy: 0.9374 - val_loss: 0.2814 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1092 - accuracy: 0.9671 - val_loss: 0.2474 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0922 - accuracy: 0.9682 - val_loss: 0.3023 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0621 - accuracy: 0.9825 - val_loss: 0.2113 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.3002 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.2877 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.3012 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0329 - accuracy: 0.9856 - val_loss: 0.4404 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.4311 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 0.3821 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.3966 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9908 - val_loss: 0.3793 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.4220 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.3884 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.3922 - val_accuracy: 0.9259 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9938 - val_loss: 0.3844 - val_accuracy: 0.9259 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0157 - accuracy: 0.9908 - val_loss: 0.3906 - val_accuracy: 0.9259 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 0.9918 - val_loss: 0.3894 - val_accuracy: 0.9259 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.3897 - val_accuracy: 0.9259 - lr: 4.0000e-05\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.3902 - val_accuracy: 0.9259 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.3919 - val_accuracy: 0.9259 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 0.3939 - val_accuracy: 0.9259 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0188 - accuracy: 0.9918 - val_loss: 0.3926 - val_accuracy: 0.9259 - lr: 8.0000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.3941 - val_accuracy: 0.9259 - lr: 8.0000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 0.9949 - val_loss: 0.3946 - val_accuracy: 0.9259 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0156 - accuracy: 0.9938 - val_loss: 0.3951 - val_accuracy: 0.9259 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.3954 - val_accuracy: 0.9259 - lr: 1.6000e-06\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.3956 - val_accuracy: 0.9259 - lr: 1.6000e-06\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.3956 - val_accuracy: 0.9259 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 1s 5ms/step\n",
      "6 CNN CV: acc=0.925926, precision=0.934783, npv=0.919355, sensitivity=0.895833, specificity=0.950000, mcc=0.849975, f1=0.914894, roc_auc=0.977431\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 21s 47ms/step - loss: 0.4771 - accuracy: 0.7710 - val_loss: 0.3650 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.1725 - accuracy: 0.9446 - val_loss: 0.2885 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1243 - accuracy: 0.9630 - val_loss: 0.3507 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0901 - accuracy: 0.9702 - val_loss: 0.4370 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0734 - accuracy: 0.9743 - val_loss: 0.4179 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0633 - accuracy: 0.9774 - val_loss: 0.4597 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0605 - accuracy: 0.9774 - val_loss: 0.4943 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.4975 - val_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0403 - accuracy: 0.9836 - val_loss: 0.5068 - val_accuracy: 0.9074 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0254 - accuracy: 0.9897 - val_loss: 0.5109 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 0.5088 - val_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 0.5417 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0208 - accuracy: 0.9897 - val_loss: 0.5418 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0202 - accuracy: 0.9918 - val_loss: 0.5455 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.5497 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9908 - val_loss: 0.5479 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 0.5542 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 0.5549 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9908 - val_loss: 0.5553 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0209 - accuracy: 0.9908 - val_loss: 0.5573 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0196 - accuracy: 0.9918 - val_loss: 0.5584 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0204 - accuracy: 0.9897 - val_loss: 0.5584 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9918 - val_loss: 0.5585 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9908 - val_loss: 0.5587 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.5591 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.5596 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0170 - accuracy: 0.9897 - val_loss: 0.5598 - val_accuracy: 0.8889 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 4s 5ms/step\n",
      "7 CNN CV: acc=0.888889, precision=0.860000, npv=0.913793, sensitivity=0.895833, specificity=0.883333, mcc=0.776475, f1=0.877551, roc_auc=0.936111\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 23ms/step - loss: 0.4882 - accuracy: 0.7577 - val_loss: 0.2448 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2075 - accuracy: 0.9292 - val_loss: 0.1860 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1095 - accuracy: 0.9620 - val_loss: 0.1664 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0946 - accuracy: 0.9692 - val_loss: 0.1376 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9692 - val_loss: 0.0770 - val_accuracy: 0.9815 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0569 - accuracy: 0.9733 - val_loss: 0.2287 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0870 - accuracy: 0.9733 - val_loss: 0.1852 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9754 - val_loss: 0.1352 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0564 - accuracy: 0.9774 - val_loss: 0.1675 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.1291 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0414 - accuracy: 0.9836 - val_loss: 0.1340 - val_accuracy: 0.9630 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.1385 - val_accuracy: 0.9537 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.1388 - val_accuracy: 0.9537 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.1450 - val_accuracy: 0.9537 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 0.1422 - val_accuracy: 0.9537 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0210 - accuracy: 0.9908 - val_loss: 0.1420 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 0.1422 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.1435 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0262 - accuracy: 0.9897 - val_loss: 0.1440 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0203 - accuracy: 0.9897 - val_loss: 0.1430 - val_accuracy: 0.9537 - lr: 4.0000e-05\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0217 - accuracy: 0.9918 - val_loss: 0.1429 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.1425 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 0.1434 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0216 - accuracy: 0.9918 - val_loss: 0.1438 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0163 - accuracy: 0.9918 - val_loss: 0.1439 - val_accuracy: 0.9537 - lr: 8.0000e-06\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0202 - accuracy: 0.9918 - val_loss: 0.1438 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.1438 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.1438 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.1440 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0159 - accuracy: 0.9918 - val_loss: 0.1440 - val_accuracy: 0.9537 - lr: 1.6000e-06\n",
      "4/4 [==============================] - 3s 0s/step\n",
      "8 CNN CV: acc=0.953704, precision=0.957447, npv=0.950820, sensitivity=0.937500, specificity=0.966667, mcc=0.906214, f1=0.947368, roc_auc=0.991319\n",
      "Saved model to disk\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 21s 26ms/step - loss: 0.4992 - accuracy: 0.7577 - val_loss: 0.3345 - val_accuracy: 0.8519 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2007 - accuracy: 0.9312 - val_loss: 0.2474 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1372 - accuracy: 0.9528 - val_loss: 0.2532 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.2960 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0865 - accuracy: 0.9641 - val_loss: 0.2912 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 0.9723 - val_loss: 0.3151 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.3032 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.2976 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0269 - accuracy: 0.9897 - val_loss: 0.3006 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0255 - accuracy: 0.9877 - val_loss: 0.2829 - val_accuracy: 0.9259 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0212 - accuracy: 0.9918 - val_loss: 0.3283 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0160 - accuracy: 0.9938 - val_loss: 0.3510 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.3572 - val_accuracy: 0.9167 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0206 - accuracy: 0.9918 - val_loss: 0.3519 - val_accuracy: 0.9167 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9908 - val_loss: 0.3474 - val_accuracy: 0.9167 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 0.9908 - val_loss: 0.3572 - val_accuracy: 0.9074 - lr: 4.0000e-05\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.3586 - val_accuracy: 0.9074 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9918 - val_loss: 0.3590 - val_accuracy: 0.9074 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0231 - accuracy: 0.9877 - val_loss: 0.3568 - val_accuracy: 0.9074 - lr: 8.0000e-06\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 0.3586 - val_accuracy: 0.9074 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.3595 - val_accuracy: 0.9074 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0149 - accuracy: 0.9938 - val_loss: 0.3604 - val_accuracy: 0.9074 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 0.3604 - val_accuracy: 0.9074 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 0.3607 - val_accuracy: 0.9074 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      " 24/122 [====>.........................] - ETA: 0s - loss: 0.0117 - accuracy: 0.9948"
     ]
    }
   ],
   "source": [
    "# Recheck mcc, auc_roc\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Function to map categorical probabilities to class labels\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def calculate_performance(test_num, pred_y, labels):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] == 1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    acc = (tp + tn) / test_num\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    npv = tn / (tn + fn + 1e-6)\n",
    "    sensitivity = tp / (tp + fn + 1e-6)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    mcc = (tp * tn - fp * fn) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + 1e-6)\n",
    "    f1 = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "    return acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn\n",
    "\n",
    "\n",
    "# Function to define and return the CNN-BiLSTM model\n",
    "def get_CNN_model(input_dim, out_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(int(input_dim / 4), return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(int(input_dim / 8), return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(int(input_dim / 4), activation='relu'))\n",
    "    model.add(Dense(int(input_dim / 8), activation='relu'))\n",
    "    model.add(Dense(out_dim, activation='softmax', name=\"Dense_2\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Folder containing CSV files\n",
    "input_dir = './New_feature_2/'\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file_name in csv_files:\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    output_base_dir = f\"./Elasfull_EN_LSTM_{file_name}/\"\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    data_ = pd.read_csv(os.path.join(input_dir, file_name))\n",
    "    data = data_.iloc[:, 1:]\n",
    "    data = data.loc[0:1081]\n",
    "\n",
    "    ones_vector1 = np.ones(480)\n",
    "    zeros_vector1 = np.zeros(602)\n",
    "    y = np.hstack((ones_vector1, zeros_vector1))\n",
    "\n",
    "    X = scale(data)\n",
    "\n",
    "    sepscores_cnn = []\n",
    "    ytest = np.ones((1, 2)) * 0.5\n",
    "    yscore = np.ones((1, 2)) * 0.5\n",
    "\n",
    "    [sample_num, input_dim] = np.shape(X)\n",
    "    out_dim = 2\n",
    "\n",
    "    # Callbacks for model training\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "    call = [EarlyStopping(monitor='val_loss', patience=25), reduce_lr]\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for i, (train, test) in enumerate(skf.split(X, y)):\n",
    "        clf_cnn = get_CNN_model(input_dim, out_dim)\n",
    "        X_train_cnn = np.reshape(X[train], (-1, 1, input_dim))\n",
    "        X_test_cnn = np.reshape(X[test], (-1, 1, input_dim))\n",
    "        y_test = to_categorical(y[test])\n",
    "        ytest = np.vstack((ytest, y_test))\n",
    "        y_test_tmp = y[test]\n",
    "\n",
    "        # Training\n",
    "        history = clf_cnn.fit(X_train_cnn, to_categorical(y[train]), validation_data=(X_test_cnn, y_test),\n",
    "                              batch_size=8, epochs=50, callbacks=call)\n",
    "\n",
    "        # Prediction\n",
    "        y_cnn_probas = clf_cnn.predict(X_test_cnn)\n",
    "        yscore = np.vstack((yscore, y_cnn_probas))\n",
    "        y_class = np.argmax(y_cnn_probas, axis=1)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn = calculate_performance(len(y_class), y_class, y[test])\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], y_cnn_probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        sepscores_cnn.append([acc, precision, npv, sensitivity, specificity, mcc, f1, roc_auc, tp, tn, fp, fn])\n",
    "        print(f'{i} CNN CV: acc={acc:.6f}, precision={precision:.6f}, npv={npv:.6f}, sensitivity={sensitivity:.6f}, '\n",
    "              f'specificity={specificity:.6f}, mcc={mcc:.6f}, f1={f1:.6f}, roc_auc={roc_auc:.6f}')\n",
    "\n",
    "        # Save the model\n",
    "        model_json = clf_cnn.to_json()\n",
    "        with open(f\"{output_base_dir}/CNN_BiLSTM_{str(i)}model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        clf_cnn.save_weights(f\"{output_base_dir}/CNN_BiLSTM_{str(i)}model.weights.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "    # Save cross-validation results\n",
    "    scores = np.array(sepscores_cnn)\n",
    "    result1 = np.mean(scores, axis=0)\n",
    "    H1 = result1.tolist()\n",
    "    sepscores_cnn.append(H1)\n",
    "    result = sepscores_cnn\n",
    "    data_csv = pd.DataFrame(data=result, columns=['acc', 'precision', 'npv', 'sensitivity', 'specificity', 'mcc', 'f1', 'roc_auc', 'tp', 'tn', 'fp', 'fn'])\n",
    "    data_csv.to_csv(f'{output_base_dir}/results_CV.csv', index=False)\n",
    "\n",
    "    # Independent test\n",
    "    test_data = data_.iloc[:, 1:]\n",
    "    test_data = test_data.loc[1082:]\n",
    "    ones_vector = np.ones(69)\n",
    "    zeros_vector = np.zeros(110)\n",
    "    yt = np.hstack((ones_vector, zeros_vector))\n",
    "\n",
    "    Xt = scale(test_data)\n",
    "    Xt = np.reshape(Xt, (-1, 1, input_dim))\n",
    "\n",
    "    sepscores_ind = []\n",
    "\n",
    "    for i in range(10):\n",
    "        with open(f\"{output_base_dir}/CNN_BiLSTM_{i}model.json\", 'r') as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        loaded_model.load_weights(f\"{output_base_dir}/CNN_BiLSTM_{i}model.weights.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        y_score = loaded_model.predict(Xt)\n",
    "        y_class = categorical_probas_to_classes(y_score)\n",
    "\n",
    "        acc, precision, npv, sensitivity, specificity, mcc, f1, tp, tn, fp, fn = calculate_performance(len(y_class), y_class, yt)\n",
    "        fpr, tpr, thresholds = roc_curve(yt, y_score[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        sepscores_ind.append([acc, precision, npv, sensitivity, specificity, mcc, f1, roc_auc, tp, tn, fp, fn])\n",
    "        print(f'{i} CNN Test: acc={acc:.6f}, precision={precision:.6f}, npv={npv:.6f}, sensitivity={sensitivity:.6f}, '\n",
    "              f'specificity={specificity:.6f}, mcc={mcc:.6f}, f1={f1:.6f}, roc_auc={roc_auc:.6f}')\n",
    "\n",
    "    # Save independent test results\n",
    "    scores = np.array(sepscores_ind)\n",
    "    result = pd.DataFrame(data=scores, columns=['acc', 'precision', 'npv', 'sensitivity', 'specificity', 'mcc', 'f1', 'roc_auc', 'tp', 'tn', 'fp', 'fn'])\n",
    "    result.to_csv(f'{output_base_dir}/results_Independent.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 387)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)              (None, 1, 193)               448532    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 1, 193)               0         ['lstm_33[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 1, 193)               772       ['dropout_33[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_34 (LSTM)              (None, 1, 96)                111360    ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 1, 96)                0         ['lstm_34[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 1, 96)                384       ['dropout_34[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_35 (LSTM)              (None, 48)                   27840     ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)        (None, 48)                   0         ['lstm_35[0][0]']             \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 48)                   0         ['dropout_35[0][0]',          \n",
      "                                                                     'dropout_35[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 48)                   0         ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 96)                   4704      ['flatten_11[0][0]']          \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 48)                   4656      ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " Dense_2 (Dense)             (None, 2)                    98        ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 598346 (2.28 MB)\n",
      "Trainable params: 597768 (2.28 MB)\n",
      "Non-trainable params: 578 (2.26 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model architecture\n",
    "with open(\"cla06_elas_new_2/CNN_BiLSTM_1model.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "\n",
    "# Reconstruct the model from the JSON file\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_weights(\"cla06_elas_new_2/CNN_BiLSTM_1model.weights.h5\")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Input (InputLayer)          [(None, 1, 387)]             0         []                            \n",
      "                                                                                                  \n",
      " LSTM (LSTM)                 (None, 1, 193)               448532    ['Input[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1, 193)               0         ['LSTM[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1, 193)               772       ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " LSTM (LSTM)                 (None, 1, 96)                111360    ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1, 96)                0         ['LSTM[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1, 96)                384       ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " LSTM (LSTM)                 (None, 48)                   27840     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 48)                   0         ['LSTM[0][0]']                \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 48)                   0         ['dropout[0][0]',             \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 48)                   0         ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 96)                   4704      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 48)                   4656      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2)                    98        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 598346 (2.28 MB)\n",
      "Trainable params: 597768 (2.28 MB)\n",
      "Non-trainable params: 578 (2.26 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model architecture\n",
    "with open(\"cla06_elas_new_2/CNN_BiLSTM_1model.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "\n",
    "# Reconstruct the model from the JSON file\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_weights(\"cla06_elas_new_2/CNN_BiLSTM_1model.weights.h5\")\n",
    "\n",
    "# Change layer names\n",
    "for layer in model.layers:\n",
    "    if 'input' in layer.name.lower():\n",
    "        layer._name = 'Input'\n",
    "    elif 'lstm' in layer.name.lower():\n",
    "        layer._name = 'LSTM'\n",
    "    elif 'dense' in layer.name.lower():\n",
    "        layer._name = layer.name.lower()  # Convert 'Dense' to 'dense'\n",
    "        layer._name = 'dense'\n",
    "    elif 'dropout' in layer.name.lower():\n",
    "        layer._name = 'dropout'\n",
    "    elif 'batch_normalization' in layer.name.lower():\n",
    "        layer._name = 'batch_normalization'\n",
    "    elif 'attention' in layer.name.lower():\n",
    "        layer._name = 'attention'\n",
    "    elif 'flatten' in layer.name.lower():\n",
    "        layer._name = 'flatten'\n",
    "\n",
    "# Display the model summary with the new names\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pydot-3.0.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\user\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\anaconda3\\lib\\site-packages (0.16)\n",
      "Collecting pyparsing>=3.0.9 (from pydot)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading pydot-3.0.3-py3-none-any.whl (35 kB)\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: pyparsing, pydot\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot pydotplus graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " InputLayer (InputLayer)     [(None, 1, 387)]             0         []                            \n",
      "                                                                                                  \n",
      " BiLSTM (LSTM)               (None, 1, 193)               448532    ['InputLayer[0][0]']          \n",
      "                                                                                                  \n",
      " DropoutLayer (Dropout)      (None, 1, 193)               0         ['BiLSTM[0][0]']              \n",
      "                                                                                                  \n",
      " BatchNorm (BatchNormalizat  (None, 1, 193)               772       ['DropoutLayer[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " BiLSTM (LSTM)               (None, 1, 96)                111360    ['BatchNorm[0][0]']           \n",
      "                                                                                                  \n",
      " DropoutLayer (Dropout)      (None, 1, 96)                0         ['BiLSTM[0][0]']              \n",
      "                                                                                                  \n",
      " BatchNorm (BatchNormalizat  (None, 1, 96)                384       ['DropoutLayer[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " BiLSTM (LSTM)               (None, 48)                   27840     ['BatchNorm[0][0]']           \n",
      "                                                                                                  \n",
      " DropoutLayer (Dropout)      (None, 48)                   0         ['BiLSTM[0][0]']              \n",
      "                                                                                                  \n",
      " AttentionLayer (Attention)  (None, 48)                   0         ['DropoutLayer[0][0]',        \n",
      "                                                                     'DropoutLayer[0][0]']        \n",
      "                                                                                                  \n",
      " FlattenLayer (Flatten)      (None, 48)                   0         ['AttentionLayer[0][0]']      \n",
      "                                                                                                  \n",
      " FullyConnected (Dense)      (None, 96)                   4704      ['FlattenLayer[0][0]']        \n",
      "                                                                                                  \n",
      " FullyConnected (Dense)      (None, 48)                   4656      ['FullyConnected[0][0]']      \n",
      "                                                                                                  \n",
      " FullyConnected (Dense)      (None, 2)                    98        ['FullyConnected[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 598346 (2.28 MB)\n",
      "Trainable params: 597768 (2.28 MB)\n",
      "Non-trainable params: 578 (2.26 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model architecture plot saved to 'model_architecture.png'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target structure is of type `<class 'keras.src.engine.keras_tensor.KerasTensor'>`\n  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 387), dtype=tf.float32, name='input_2'), name='inpu...\nHowever the input is a sequence (<class 'list'>) of length 0.\n  []\nnest cannot guarantee that it is safe to map one to the other.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel architecture plot saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_architecture.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#  JSON  H5\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_model.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m     46\u001b[0m     json_file\u001b[38;5;241m.\u001b[39mwrite(model_json)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3274\u001b[0m, in \u001b[0;36mModel.to_json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a JSON string containing the network configuration.\u001b[39;00m\n\u001b[0;32m   3263\u001b[0m \n\u001b[0;32m   3264\u001b[0m \u001b[38;5;124;03m    To load a network from a JSON save file, use\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3272\u001b[0m \u001b[38;5;124;03m        A JSON string.\u001b[39;00m\n\u001b[0;32m   3273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3274\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_updated_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[0;32m   3276\u001b[0m         model_config, default\u001b[38;5;241m=\u001b[39mjson_utils\u001b[38;5;241m.\u001b[39mget_json_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3277\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3148\u001b[0m, in \u001b[0;36mModel._updated_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Util shared between different serialization methods.\u001b[39;00m\n\u001b[0;32m   3142\u001b[0m \n\u001b[0;32m   3143\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;124;03m    Model config with Keras version information added.\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m keras_version\n\u001b[1;32m-> 3148\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3149\u001b[0m model_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   3151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config,\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: keras_version,\n\u001b[0;32m   3153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m\"\u001b[39m: backend\u001b[38;5;241m.\u001b[39mbackend(),\n\u001b[0;32m   3154\u001b[0m }\n\u001b[0;32m   3155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_config\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py:784\u001b[0m, in \u001b[0;36mFunctional.get_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# Check whether the class has a constructor compatible with a Functional\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# model or if it has a custom constructor.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_functional_like_constructor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# Only return a Functional config if the constructor is the same\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# as that of a Functional model. This excludes subclassed Functional\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# models with a custom __init__.\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43mget_network_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Try to autogenerate config\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     xtra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(config\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py:1607\u001b[0m, in \u001b[0;36mget_network_config\u001b[1;34m(network, serialize_layer_fn, config)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     new_node_index \u001b[38;5;241m=\u001b[39m node_conversion_map[node_key]\n\u001b[0;32m   1604\u001b[0m     model_inputs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1605\u001b[0m         tf_utils\u001b[38;5;241m.\u001b[39mListWrapper([layer\u001b[38;5;241m.\u001b[39mname, new_node_index, tensor_index])\n\u001b[0;32m   1606\u001b[0m     )\n\u001b[1;32m-> 1607\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nested_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_inputs\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;66;03m# Preserve external Keras compat for Models with single input.\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(model_inputs):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:533\u001b[0m, in \u001b[0;36mpack_sequence_as\u001b[1;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.pack_sequence_as\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpack_sequence_as\u001b[39m(structure, flat_sequence, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    421\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a given flattened sequence packed into a given structure.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m    TypeError: `structure` is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:844\u001b[0m, in \u001b[0;36mpack_sequence_as\u001b[1;34m(modality, structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a given flattened sequence packed into a given structure.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \n\u001b[0;32m    723\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m  non-sortable keys.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[1;32m--> 844\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_fn\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[0;32m    848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_pack_sequence_as(structure, flat_sequence)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:878\u001b[0m, in \u001b[0;36m_tf_core_pack_sequence_as\u001b[1;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nested_fn(structure):\n\u001b[0;32m    877\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_sequence) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    879\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target structure is of type `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHowever the input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis a sequence (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) of length \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mnest cannot \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguarantee that it is safe to map one to the other.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;28mtype\u001b[39m(structure),\n\u001b[0;32m    883\u001b[0m             truncate(structure, \u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m    884\u001b[0m             \u001b[38;5;28mtype\u001b[39m(flat_sequence),\n\u001b[0;32m    885\u001b[0m             \u001b[38;5;28mlen\u001b[39m(flat_sequence),\n\u001b[0;32m    886\u001b[0m             truncate(flat_sequence, \u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m    887\u001b[0m         )\n\u001b[0;32m    888\u001b[0m     )\n\u001b[0;32m    889\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_sequence[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The target structure is of type `<class 'keras.src.engine.keras_tensor.KerasTensor'>`\n  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 387), dtype=tf.float32, name='input_2'), name='inpu...\nHowever the input is a sequence (<class 'list'>) of length 0.\n  []\nnest cannot guarantee that it is safe to map one to the other."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "#  \n",
    "plot_model(model, to_file='model_architecture_rename.png', show_shapes=True, show_layer_names=True, rankdir='TB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
